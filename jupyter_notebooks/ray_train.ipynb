{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9b6c7b4-cccb-4f1d-86bd-d2b0ec60bde6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import ScalingConfig,RunConfig\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models import resnet18 , ResNet18_Weights\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "from torch.utils.data import Subset,DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.classification import Accuracy\n",
    "from PIL import Image\n",
    "from filelock import FileLock\n",
    "from pathlib import Path\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5352278e-e560-4145-9561-a479807ac37c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../marimo_notebooks/data\n",
       "    Split: Test"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CIFAR10(root=\"../marimo_notebooks/data\",download=True,train=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "925827ef-e757-4c76-8926-1c873cb48faf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32>, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data contains of a PIL image and the label\n",
    "next(iter(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9205da88-0ee7-45c8-8835-7c3d196f2c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_idx = data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46641dcc-4f1b-409c-b488-53966744e3da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shoaib/code/anyscale-projects/anyscale-demo/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18(weights=ResNet18_Weights)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0b185cc-5db5-4d35-90d3-bcd9769e29c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cifar_dataloader(batch_size):\n",
    "    imagenet_transforms = ResNet18_Weights.IMAGENET1K_V1.transforms\n",
    "    full_transform = Compose([ToTensor(),imagenet_transforms()])\n",
    "    with FileLock(os.path.expanduser(\"~/cifar_data.lock\")):\n",
    "        train = CIFAR10(\n",
    "            root=\"~/cifar_data\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=full_transform,\n",
    "        )\n",
    "        valid = CIFAR10(\n",
    "            root=\"~/cifar_data\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=full_transform,\n",
    "        )\n",
    "    train_sub = Subset(train,indices=range(300))\n",
    "    valid_sub = Subset(valid,indices=range(300))\n",
    "    # dataloaders to get data in batches\n",
    "    train_dataloader = DataLoader(train_sub, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_sub, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, valid_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccc873de-1c55-4d86-bc0d-9be934ed340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, in_channels=3, hidden_features=128, out_features=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, kernel_size=2, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((8, 8)),  # force to fixed H Ã— W\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 8 * 8, hidden_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_features, out_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2919c541-40c1-41cd-af91-7e2610bbb33e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_func(config):\n",
    "\n",
    "    epochs = config[\"epochs\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "    \n",
    "    \n",
    "    # use detected device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    # metrics\n",
    "    accuracy = Accuracy(task=\"multiclass\", num_classes=config[\"num_classes\"]).to(device)\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    num_batches = 0.0\n",
    "\n",
    "    checkpoint_path = Path(\"../marimo_notebooks/data/checkpoint\")\n",
    "    checkpoint_path.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "    #device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "    # model = resnet18(weights=weights)\n",
    "    model = SimpleModel(in_channels=3,hidden_features=128,out_features=10)\n",
    "    # for parameter in model.parameters():\n",
    "    #     parameter.requires_grad = False\n",
    "    # model.fc = nn.Linear(512,config[\"num_classes\"],bias=True)\n",
    "    \n",
    "    model = ray.train.torch.prepare_model(model)\n",
    " \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    train_dataloader, valid_dataloader = get_cifar_dataloader(batch_size=batch_size)\n",
    "    train_dataloader = ray.train.torch.prepare_data_loader(train_dataloader)\n",
    "    valid_dataloader = ray.train.torch.prepare_data_loader(valid_dataloader)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # checking if training is scheduled in a distributed setting or not.\n",
    "        if ray.train.get_context().get_world_size() > 1:\n",
    "            train_dataloader.sampler.set_epoch(epoch)\n",
    "        model.train()\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            x, y = batch[0], batch[1]\n",
    "            y_preds = model(x)\n",
    "            y_labels = y_preds.argmax(dim=1)\n",
    "            loss = loss_fn(y_preds,y)\n",
    "            acc = accuracy(y_labels,y)\n",
    "            train_loss +=  loss.item()\n",
    "            train_acc += acc.item()\n",
    "        train_loss /=len(train_dataloader)\n",
    "        train_acc /=len(train_dataloader)\n",
    "        metrics = {\"epoch\":epoch,\"train_loss\":train_loss, \"train_acc\":train_acc}\n",
    "\n",
    "        ray.train.report(metrics)\n",
    "        if ray.train.get_context().get_world_rank() == 0:\n",
    "            print(metrics)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eead0973-1ef0-4c91-b313-f986c12cc0a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_batch_size = 10\n",
    "num_workers = 8\n",
    "use_gpu = False\n",
    "\n",
    "train_config = {\n",
    "    \"lr\": 1e-2,\n",
    "    \"epochs\": 10,\n",
    "    \"num_classes\": 10,\n",
    "    \"batch_size\": global_batch_size // num_workers,\n",
    "    \"weight_decay\": 1e-2\n",
    "}\n",
    "scaling_config = ScalingConfig(num_workers=num_workers, use_gpu=use_gpu)\n",
    "run_config = RunConfig(\n",
    "    storage_path=str(Path(\"../marimo_notebooks/data/storage_path\").resolve()), \n",
    "    name=f\"ray_train_torch_run-{uuid.uuid4().hex}\",    \n",
    ")\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_func,\n",
    "    train_loop_config=train_config,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77710997-5f7f-479f-a4da-1f4549d71036",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-02 13:14:28,171\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 13:14:28 (running for 00:00:00.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 9.0/10 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-08-02_12-51-11_285675_74959/artifacts/2025-08-02_13-14-28/ray_train_torch_run-a5e79510deaa4859836740ec8ef14248/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-08-02 13:14:33 (running for 00:00:05.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 9.0/10 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-08-02_12-51-11_285675_74959/artifacts/2025-08-02_13-14-28/ray_train_torch_run-a5e79510deaa4859836740ec8ef14248/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-08-02 13:14:38 (running for 00:00:10.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 9.0/10 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-08-02_12-51-11_285675_74959/artifacts/2025-08-02_13-14-28/ray_train_torch_run-a5e79510deaa4859836740ec8ef14248/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-08-02 13:14:43 (running for 00:00:15.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 9.0/10 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-08-02_12-51-11_285675_74959/artifacts/2025-08-02_13-14-28/ray_train_torch_run-a5e79510deaa4859836740ec8ef14248/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-08-02 13:14:48 (running for 00:00:20.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 9.0/10 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-08-02_12-51-11_285675_74959/artifacts/2025-08-02_13-14-28/ray_train_torch_run-a5e79510deaa4859836740ec8ef14248/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-08-02 13:14:53 (running for 00:00:25.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 9.0/10 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-08-02_12-51-11_285675_74959/artifacts/2025-08-02_13-14-28/ray_train_torch_run-a5e79510deaa4859836740ec8ef14248/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-02 13:14:54,644\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/shoaib/code/anyscale-projects/anyscale-demo/marimo_notebooks/data/storage_path/ray_train_torch_run-a5e79510deaa4859836740ec8ef14248' in 0.0050s.\n",
      "2025-08-02 13:14:54,646\tINFO tune.py:1041 -- Total run time: 26.48 seconds (26.46 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 13:14:54 (running for 00:00:26.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 9.0/10 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-08-02_12-51-11_285675_74959/artifacts/2025-08-02_13-14-28/ray_train_torch_run-a5e79510deaa4859836740ec8ef14248/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n",
      "Training result: Result(\n",
      "  metrics={'epoch': 9, 'train_loss': 2.3948231630960457, 'train_acc': 0.1095295858409676},\n",
      "  path='/Users/shoaib/code/anyscale-projects/anyscale-demo/marimo_notebooks/data/storage_path/ray_train_torch_run-a5e79510deaa4859836740ec8ef14248/TorchTrainer_3ca76_00000_0_2025-08-02_13-14-28',\n",
      "  filesystem='local',\n",
      "  checkpoint=None\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(autoscaler +51m44s)\u001b[0m [autoscaler] Downscaling node i-04494db17bc8de61d (node IP: 100.78.239.19) due to node idle termination.\n",
      "\u001b[36m(autoscaler +51m44s)\u001b[0m [autoscaler] Downscaling node i-0e47beae8cd6fcbc6 (node IP: 100.80.166.40) due to node idle termination.\n"
     ]
    }
   ],
   "source": [
    "result = trainer.fit()\n",
    "print(f\"Training result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ead92d3-a9d2-4591-b980-b645028aaf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d226b-52c0-493f-8fb3-ea67f60f2395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
